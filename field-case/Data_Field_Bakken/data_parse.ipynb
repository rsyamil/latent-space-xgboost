{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique wells with completion data:  14638\n",
      "Number of unique wells with well testing data:  14739\n",
      "Number of unique wells with production data:  988\n"
     ]
    }
   ],
   "source": [
    "''' Script to parse data from the excel spreadsheet into pickle objects\n",
    "'''\n",
    "\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import pickle\n",
    "\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "\n",
    "#load completion data\n",
    "comp_data = pd.read_csv(\"DATA-RAW/StimDump_6-18-2020.csv\")\n",
    "num_wells = len(comp_data['FileNumber'].unique())\n",
    "print(\"Number of unique wells with completion data: \", num_wells)\n",
    "\n",
    "#load well testing data\n",
    "wtest_data = pd.read_csv(\"DATA-RAW/StimDump_6-18-2020_Prod_Test.csv\")\n",
    "num_wells = len(wtest_data['FileNo'].unique())\n",
    "print(\"Number of unique wells with well testing data: \", num_wells)\n",
    "\n",
    "#load production data\n",
    "prod_data = pd.read_csv(\"DATA-RAW/MultiFieldsData-3.csv\")\n",
    "num_wells = len(prod_data['File_No'].unique())\n",
    "print(\"Number of unique wells with production data: \", num_wells)\n",
    "\n",
    "#get oil, water and gas production per day\n",
    "prod_data['BBLS_Oil'] = prod_data['BBLS_Oil']/prod_data['Days']\n",
    "prod_data['BBLS_Water'] = prod_data['BBLS_Water']/prod_data['Days']\n",
    "prod_data['MCF_Prod'] = prod_data['MCF_Prod']/prod_data['Days']\n",
    "\n",
    "#replace NaN & inf with zeros\n",
    "prod_data = prod_data.fillna(0)\n",
    "prod_data.replace(np.inf, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder matrix \n",
    "max_timesteps = 130\n",
    "\n",
    "#keys for each well:\n",
    "#'Prod' = 'BBLS_Oil'+'BBLS_Water'+'MCF_Prod'\n",
    "#'Comp' = 'Vol', 'Lbs_Prop', 'MTPress', 'MTRate_N', 'Stages'\n",
    "#'Loc' = 'Latitude', 'Longitude'\n",
    "#'Cumm' = 'Cumm_Oil', 'Cumm_Water', 'Cumm_Gas',\n",
    "attributes = ['FileNo', 'FieldName', \n",
    "              'Prod', 'Prod_Control',  \n",
    "              'Cumm', \n",
    "              'Loc', \n",
    "              'Comp']\n",
    "\n",
    "#unique well identifiers\n",
    "FileNo = np.array(prod_data['FileNo'].unique()).astype('str')\n",
    "\n",
    "#store all data\n",
    "DATA = dict((fno, dict((attr, None) for attr in attributes)) for fno in FileNo)\n",
    "\n",
    "#read production data, prepare data, sort by time\n",
    "for idx, file in enumerate(FileNo):\n",
    "    \n",
    "    #get rows for this particular well only\n",
    "    _ = prod_data[prod_data['FileNo']==file.astype('int32')]\n",
    "    \n",
    "    DATA[file]['FileNo'] = file\n",
    "    DATA[file]['FieldName'] = _['FieldName'].iloc[0]\n",
    "    \n",
    "    coords = np.zeros([2,])\n",
    "    coords[0] = _['Latitude'].iloc[0]\n",
    "    coords[1] = _['Longitude'].iloc[0]\n",
    "    DATA[file]['Loc'] = coords\n",
    "\n",
    "    DATA[file]['Cumm'] = np.array((_['OilWaterGasCums'].iloc[0]).strip().split('|')).astype('int32')\n",
    "\n",
    "    #production profiles\n",
    "    prod_oil = np.zeros([max_timesteps,])\n",
    "    prod_water = np.zeros([max_timesteps,])\n",
    "    prod_gas = np.zeros([max_timesteps,])\n",
    "    \n",
    "    _oil = _['BBLS_Oil']\n",
    "    _water = _['BBLS_Water']\n",
    "    _gas = _['MCF_Prod']\n",
    "    _row,_col = _.shape\n",
    "    prod_oil[0:_row] = np.flip(_oil, axis=0)\n",
    "    prod_water[0:_row] = np.flip(_water, axis=0)\n",
    "    prod_gas[0:_row] = np.flip(_gas, axis=0)\n",
    "    prod = np.stack((prod_oil, prod_water, prod_gas), axis=-1)\n",
    "    DATA[file]['Prod'] = prod\n",
    "    \n",
    "    #create synthetic controls\n",
    "    _ = np.sum((prod[:, 0], prod[:, 1], prod[:, 2]), axis=0)\n",
    "    DATA[file]['Prod_Control'] = np.where(_==0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of wells removed, with no completion data :  50\n",
      "Num of wells removed, refracked :  52\n",
      "Num of wells with prod data & comp data:  886\n"
     ]
    }
   ],
   "source": [
    "#count for info, for now only accept wells with no intervention job\n",
    "count_empty = 0\n",
    "count_refrack = 0\n",
    "\n",
    "#read completion data\n",
    "for idx, file in enumerate(FileNo):\n",
    "    \n",
    "    #get rows for this particular well only\n",
    "    _ = comp_data[comp_data['FileNumber']==file.astype('int32')]\n",
    "    \n",
    "    #if no row is returned (comp data not available), delete from the original DATA\n",
    "    if _.empty:\n",
    "        del DATA[file]\n",
    "        count_empty = count_empty+1\n",
    "        continue\n",
    "        \n",
    "    #if more than 1 row is returned (intervention job), delete from the original DATA\n",
    "    #we need better ways to handle this later\n",
    "    _row,_col = _.shape\n",
    "    if _row > 1:\n",
    "        del DATA[file]\n",
    "        count_refrack = count_refrack+1\n",
    "        continue\n",
    "        \n",
    "    #populate the completion parameters\n",
    "    comps = np.zeros([5,])\n",
    "\n",
    "    if _['Units'].iloc[0] == \"Gal\":\n",
    "        #convert to Bbl\n",
    "        comps[0] = _['Vol'].iloc[0]*0.0238095238\n",
    "    else:\n",
    "        comps[0] = _['Vol'].iloc[0]\n",
    "    comps[1] = _['Lbs_Prop'].iloc[0]\n",
    "    comps[2] = _['MTPress'].iloc[0]\n",
    "    comps[3] = _['MTRate_N'].iloc[0]\n",
    "    comps[4] = _['Stages'].iloc[0]\n",
    "    DATA[file]['Comp'] = comps\n",
    "\n",
    "#get the final keys for wells with prod data & comp data\n",
    "keys = list(DATA.keys())\n",
    "\n",
    "print(\"Num of wells removed, with no completion data : \", count_empty)\n",
    "print(\"Num of wells removed, refracked : \", count_refrack)\n",
    "print(\"Num of wells with prod data & comp data: \", len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump/read functions\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the raw data\n",
    "save_obj(DATA, 'DATA-raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
